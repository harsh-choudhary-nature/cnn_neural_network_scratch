{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e489f3e-fec6-436a-8358-acf03aa54031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8077d448-2bb1-4eba-954e-d7c15abd4543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "mnist = fetch_openml(name='mnist_784', version=1, cache=True, parser='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f2b5a83-ff8d-4d78-8d3c-e216eda5304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features (X) and labels (y)\n",
    "X, y = mnist.data, mnist.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccea8431-9913-4c84-8b65-bd15aa96f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93b5fc0a-c217-4913-a493-e9ad855c0912",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
    "# X_train = X_train.values\n",
    "# X_test = X_test.values\n",
    "Y_train = Y_train.astype('float').values\n",
    "Y_test = Y_test.astype('float').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df20065c-6327-44eb-abfb-41279eef1eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000, 784)\n",
      "(56000, 1)\n",
      "(14000, 784)\n",
      "(14000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "Y_train = Y_train.reshape(-1,1)\n",
    "# print(Y_train)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "Y_test = Y_test.reshape(-1,1)\n",
    "print(Y_test.shape)\n",
    "\n",
    "Y_train = Y_train/10\n",
    "Y_test = Y_test/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1844bfb-0a3d-485a-9fe9-b645dbf97dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'two layers. Layer 1 with 89 output neurons with tanh activation. Layer 2\\nwith ten output neuron and sigmoid activation. use mean squared loss'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''two layers. Layer 1 with 89 output neurons with tanh activation. Layer 2\n",
    "with ten output neuron and sigmoid activation. use mean squared loss'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b40f4a62-e972-4285-a0f7-e4991a9f5790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "from neuralNetwork import NeuralNetwork\n",
    "from layer import DenseLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a1c5ca0-fa9a-4847-8b64-dcf83a36a073",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = NeuralNetwork(layers=[DenseLayer(),DenseLayer()],neurons_per_layer=[89,10],activation_per_layer=[util.TanhLayer(),util.SigmoidLayer()],lr=0.01,batch_size=32,epochs=50,loss_obj=util.MeanSquaredLossLayer(),X=X_train,Y=Y_train)\n",
    "\n",
    "model1.init_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8947fb16-60de-41c3-b7c6-2b327f7885e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: Loss = 4715.74632863737\n",
      "epoch 1: Loss = 4183.560744894692\n",
      "epoch 2: Loss = 3741.7165331112437\n",
      "epoch 3: Loss = 3414.251581554747\n",
      "epoch 4: Loss = 3175.7553961800645\n",
      "epoch 5: Loss = 3003.4392170592964\n",
      "epoch 6: Loss = 2881.0979363518077\n",
      "epoch 7: Loss = 2790.100496947476\n",
      "epoch 8: Loss = 2719.0895093828267\n",
      "epoch 9: Loss = 2661.0539212805347\n",
      "epoch 10: Loss = 2611.8509951991905\n",
      "epoch 11: Loss = 2568.7837784197845\n",
      "epoch 12: Loss = 2530.798317007969\n",
      "epoch 13: Loss = 2497.4373550963564\n",
      "epoch 14: Loss = 2467.299093358266\n",
      "epoch 15: Loss = 2439.445756581318\n",
      "epoch 16: Loss = 2413.7486525975614\n",
      "epoch 17: Loss = 2389.843735323851\n",
      "epoch 18: Loss = 2367.397181509692\n",
      "epoch 19: Loss = 2346.5663730430297\n",
      "epoch 20: Loss = 2326.8968864424833\n",
      "epoch 21: Loss = 2307.875637755165\n",
      "epoch 22: Loss = 2289.5682325911494\n",
      "epoch 23: Loss = 2272.071027511528\n",
      "epoch 24: Loss = 2255.344000910038\n",
      "epoch 25: Loss = 2239.150421062362\n",
      "epoch 26: Loss = 2223.272307731676\n",
      "epoch 27: Loss = 2207.6790385701747\n",
      "epoch 28: Loss = 2192.347998237163\n",
      "epoch 29: Loss = 2177.3396573334885\n",
      "epoch 30: Loss = 2162.691268055742\n",
      "epoch 31: Loss = 2148.2884985895444\n",
      "epoch 32: Loss = 2134.191533418501\n",
      "epoch 33: Loss = 2120.2503700401376\n",
      "epoch 34: Loss = 2106.2945649483972\n",
      "epoch 35: Loss = 2092.2400203977304\n",
      "epoch 36: Loss = 2078.174841950812\n",
      "epoch 37: Loss = 2064.1281316343343\n",
      "epoch 38: Loss = 2050.0378183046296\n",
      "epoch 39: Loss = 2035.7872512663475\n",
      "epoch 40: Loss = 2021.4100486365248\n",
      "epoch 41: Loss = 2006.9214786089883\n",
      "epoch 42: Loss = 1992.2182615807956\n",
      "epoch 43: Loss = 1977.2187771120643\n",
      "epoch 44: Loss = 1961.878811871281\n",
      "epoch 45: Loss = 1946.083224626114\n",
      "epoch 46: Loss = 1929.5949288730621\n",
      "epoch 47: Loss = 1912.1653109545016\n",
      "epoch 48: Loss = 1893.6252666653677\n",
      "epoch 49: Loss = 1873.6295774989667\n"
     ]
    }
   ],
   "source": [
    "model1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "679b93bc-4e3e-4da2-ae72-e97e0434eae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95741718 0.99991444 0.99998432 0.99999993 0.99641237 0.99993371\n",
      " 0.99998898 0.95973866 0.99988836 0.99694461]\n",
      "[0.8]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "Y_pred_test = model1.predict(X_test)\n",
    "print(Y_pred_test[0])\n",
    "print(Y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c7af551-ebdd-407e-b52d-09845aa38435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c8dbe7a-0a10-473d-ab27-e0dfe309b73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "Y_pred_test_labels = np.argmax(Y_pred_test,axis=0,keepdims=True)\n",
    "print(\"accuracy:\",np.sum(Y_pred_test_labels/10==Y_test)/Y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "531eb8e5-a597-4c05-90b6-c470d7ac71d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'two layers. Layer 1 with 89 output neurons with tanh activation. Layer\\n2 with ten output neuron and linear activation. use softmax with cross\\nentropy loss.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''two layers. Layer 1 with 89 output neurons with tanh activation. Layer\n",
    "2 with ten output neuron and linear activation. use softmax with cross\n",
    "entropy loss.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a77d6db-832c-4dd0-88f2-fdbd828b671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "695e4f5e-42e7-4de0-b633-c119af0b5091",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False,categories='auto')\n",
    "# print((Y_train*10)[0])\n",
    "Y_train_onehot = encoder.fit_transform(Y_train*10)\n",
    "Y_test_onehot = encoder.fit_transform(Y_test*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aca19737-e934-4669-8a01-efbd8222e7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000, 10)\n",
      "(14000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_onehot.shape)\n",
    "print(Y_test_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ba010d2-7171-4134-9390-0ffd2869ca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = NeuralNetwork(layers=[DenseLayer(),DenseLayer()],neurons_per_layer=[89,10],activation_per_layer=[util.TanhLayer(),util.SoftmaxLayer()],lr=0.01,batch_size=32,epochs=50,loss_obj=util.CrossEntropyLossLayer(),X=X_train,Y=Y_train_onehot)\n",
    "\n",
    "model2.init_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bdf619a-87c4-46df-ad6b-0d49409c16cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: Loss = 10569.953321098761\n",
      "epoch 1: Loss = 4414.026975803615\n",
      "epoch 2: Loss = 3160.7903480119876\n",
      "epoch 3: Loss = 2558.7869469514685\n",
      "epoch 4: Loss = 2183.406521808038\n",
      "epoch 5: Loss = 1919.0649945571934\n",
      "epoch 6: Loss = 1719.543192934177\n",
      "epoch 7: Loss = 1563.6090878366326\n",
      "epoch 8: Loss = 1438.2443271224226\n",
      "epoch 9: Loss = 1335.2346204963117\n",
      "epoch 10: Loss = 1248.912289588836\n",
      "epoch 11: Loss = 1175.7945794782497\n",
      "epoch 12: Loss = 1112.9879148588839\n",
      "epoch 13: Loss = 1058.8394367253588\n",
      "epoch 14: Loss = 1011.5221108231782\n",
      "epoch 15: Loss = 970.2121571096934\n",
      "epoch 16: Loss = 934.0894871843017\n",
      "epoch 17: Loss = 902.3146778726892\n",
      "epoch 18: Loss = 874.275688209751\n",
      "epoch 19: Loss = 849.6547765748913\n",
      "epoch 20: Loss = 827.9320433672641\n",
      "epoch 21: Loss = 808.7216866410737\n",
      "epoch 22: Loss = 791.6876918282461\n",
      "epoch 23: Loss = 776.4342142955438\n",
      "epoch 24: Loss = 762.7963741708156\n",
      "epoch 25: Loss = 750.4965524288463\n",
      "epoch 26: Loss = 739.3214978617941\n",
      "epoch 27: Loss = 729.1448609723843\n",
      "epoch 28: Loss = 719.8192746001919\n",
      "epoch 29: Loss = 711.2613926320948\n",
      "epoch 30: Loss = 703.3682489413947\n",
      "epoch 31: Loss = 696.1093269388423\n",
      "epoch 32: Loss = 689.3938262893865\n",
      "epoch 33: Loss = 683.1681771879854\n",
      "epoch 34: Loss = 677.3954186593271\n",
      "epoch 35: Loss = 671.9756613742035\n",
      "epoch 36: Loss = 666.8150575873207\n",
      "epoch 37: Loss = 661.9367986073419\n",
      "epoch 38: Loss = 657.3113900232061\n",
      "epoch 39: Loss = 652.8822934773552\n",
      "epoch 40: Loss = 648.6142826866231\n",
      "epoch 41: Loss = 644.5461761053393\n",
      "epoch 42: Loss = 640.6231560470287\n",
      "epoch 43: Loss = 636.8422580329044\n",
      "epoch 44: Loss = 633.2267127651326\n",
      "epoch 45: Loss = 629.7110862873405\n",
      "epoch 46: Loss = 626.2861076753724\n",
      "epoch 47: Loss = 622.9741778117111\n",
      "epoch 48: Loss = 619.752133002993\n",
      "epoch 49: Loss = 616.5967954886346\n"
     ]
    }
   ],
   "source": [
    "model2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b36efcf1-2f9f-46fe-bf5e-c1a9c31f33d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test_onehot = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38717c22-b7c6-4481-bca2-1f5ac10a7401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\n",
      "[0.8]\n"
     ]
    }
   ],
   "source": [
    "Y_pred_test_labels = np.argmax(Y_pred_test_onehot,axis=1,keepdims=True)\n",
    "print(Y_pred_test_labels[0])\n",
    "print(Y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad93c6bd-5a22-485d-a735-c7ccbbaad29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = np.array([[1,2,3],\n",
    "#              [4,5,6]])\n",
    "# np.argmax(A,axis=1,keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8099acb1-b7da-48ac-92c6-1a1c32732227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8567142857142858\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\",np.sum(Y_pred_test_labels/10==Y_test)/Y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "729cd76c-1450-4585-83a6-34945a1dc77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: Loss = 613.52744825338\n",
      "epoch 1: Loss = 610.546148644722\n",
      "epoch 2: Loss = 607.6110672325952\n",
      "epoch 3: Loss = 604.7308280638449\n",
      "epoch 4: Loss = 601.9056426553574\n",
      "epoch 5: Loss = 599.1311226062013\n",
      "epoch 6: Loss = 596.4582983973057\n",
      "epoch 7: Loss = 593.8502050789344\n",
      "epoch 8: Loss = 591.2778187977278\n",
      "epoch 9: Loss = 588.7530943534182\n",
      "epoch 10: Loss = 586.2766778062157\n",
      "epoch 11: Loss = 583.8466098784126\n",
      "epoch 12: Loss = 581.4713768166761\n",
      "epoch 13: Loss = 579.1271412325274\n",
      "epoch 14: Loss = 576.8156769143134\n",
      "epoch 15: Loss = 574.5673903879126\n",
      "epoch 16: Loss = 572.3615613576516\n",
      "epoch 17: Loss = 570.1840223353983\n",
      "epoch 18: Loss = 568.0203105628051\n",
      "epoch 19: Loss = 565.87965529728\n",
      "epoch 20: Loss = 563.8179993699131\n",
      "epoch 21: Loss = 561.7837075948837\n",
      "epoch 22: Loss = 559.7668450906602\n",
      "epoch 23: Loss = 557.7735739654753\n",
      "epoch 24: Loss = 555.825012264384\n",
      "epoch 25: Loss = 553.8979523962082\n",
      "epoch 26: Loss = 551.9978502825559\n",
      "epoch 27: Loss = 550.08783708496\n",
      "epoch 28: Loss = 548.1633712050493\n",
      "epoch 29: Loss = 546.3152667699595\n",
      "epoch 30: Loss = 544.4895275498386\n",
      "epoch 31: Loss = 542.6736034466937\n",
      "epoch 32: Loss = 540.8603567237136\n",
      "epoch 33: Loss = 539.0416968498947\n",
      "epoch 34: Loss = 537.271898908873\n",
      "epoch 35: Loss = 535.5281815968207\n",
      "epoch 36: Loss = 533.8098017433683\n",
      "epoch 37: Loss = 532.1292214783406\n",
      "epoch 38: Loss = 530.4688398070517\n",
      "epoch 39: Loss = 528.8188870553605\n",
      "epoch 40: Loss = 527.1917594927601\n",
      "epoch 41: Loss = 525.5631643651867\n",
      "epoch 42: Loss = 523.9414145131612\n",
      "epoch 43: Loss = 522.3059104382701\n",
      "epoch 44: Loss = 520.6930883426829\n",
      "epoch 45: Loss = 519.0904342612076\n",
      "epoch 46: Loss = 517.4991623770164\n",
      "epoch 47: Loss = 515.9300006096811\n",
      "epoch 48: Loss = 514.3932943364451\n",
      "epoch 49: Loss = 512.8704955510967\n",
      "epoch 50: Loss = 511.3541893187617\n",
      "epoch 51: Loss = 509.8500729215098\n",
      "epoch 52: Loss = 508.35110416111604\n",
      "epoch 53: Loss = 506.8759160530371\n",
      "epoch 54: Loss = 505.42358867315744\n",
      "epoch 55: Loss = 503.95928235082994\n",
      "epoch 56: Loss = 502.50023665894804\n",
      "epoch 57: Loss = 501.079214784283\n",
      "epoch 58: Loss = 499.62199124851344\n",
      "epoch 59: Loss = 498.19397417749394\n",
      "epoch 60: Loss = 496.77541475506166\n",
      "epoch 61: Loss = 495.3832904194351\n",
      "epoch 62: Loss = 493.9708932134218\n",
      "epoch 63: Loss = 492.5696932144843\n",
      "epoch 64: Loss = 491.2104781784825\n",
      "epoch 65: Loss = 489.86111408562556\n",
      "epoch 66: Loss = 488.52029088895597\n",
      "epoch 67: Loss = 487.1831689244374\n",
      "epoch 68: Loss = 485.87542996366386\n",
      "epoch 69: Loss = 484.5542381380231\n",
      "epoch 70: Loss = 483.2519000085797\n",
      "epoch 71: Loss = 481.9648795266975\n",
      "epoch 72: Loss = 480.64642561048015\n",
      "epoch 73: Loss = 479.3235853731443\n",
      "epoch 74: Loss = 478.0390608778237\n",
      "epoch 75: Loss = 476.7625866183037\n",
      "epoch 76: Loss = 475.50809877542764\n",
      "epoch 77: Loss = 474.25076729026864\n",
      "epoch 78: Loss = 473.0008119710693\n",
      "epoch 79: Loss = 471.7738814958817\n",
      "epoch 80: Loss = 470.5683661065129\n",
      "epoch 81: Loss = 469.3781005191098\n",
      "epoch 82: Loss = 468.22333001403064\n",
      "epoch 83: Loss = 467.07891688263294\n",
      "epoch 84: Loss = 465.9391531680827\n",
      "epoch 85: Loss = 464.7963542306393\n",
      "epoch 86: Loss = 463.64396756939647\n",
      "epoch 87: Loss = 462.5269033202348\n",
      "epoch 88: Loss = 461.4123401309601\n",
      "epoch 89: Loss = 460.30374316148874\n",
      "epoch 90: Loss = 459.1931364678039\n",
      "epoch 91: Loss = 458.0803596415411\n",
      "epoch 92: Loss = 456.967464900726\n",
      "epoch 93: Loss = 455.891048849509\n",
      "epoch 94: Loss = 454.8402255729929\n",
      "epoch 95: Loss = 453.8010608265474\n",
      "epoch 96: Loss = 452.7711027864395\n",
      "epoch 97: Loss = 451.747447483637\n",
      "epoch 98: Loss = 450.72249466645275\n",
      "epoch 99: Loss = 449.6870298076919\n"
     ]
    }
   ],
   "source": [
    "model2.epochs = 100\n",
    "model2.lr = 1\n",
    "model2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4f2d007-5a05-4043-b806-bf020b8a00be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\n",
      "[0.8]\n",
      "accuracy: 0.8726428571428572\n"
     ]
    }
   ],
   "source": [
    "Y_pred_test_onehot = model2.predict(X_test)\n",
    "Y_pred_test_labels = np.argmax(Y_pred_test_onehot,axis=1,keepdims=True)\n",
    "print(Y_pred_test_labels[0])\n",
    "print(Y_test[0])\n",
    "print(\"accuracy:\",np.sum(Y_pred_test_labels/10==Y_test)/Y_test.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
